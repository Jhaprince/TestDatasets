 this paper presents a new measure of semantic similarity in an is-a taxonomy, based on the notion of information content. experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66).
 with an increasing number of malicious attacks, the number of people and organizations falling prey to social engineering attacks is proliferating. despite considerable research in mitigation systems, attackers continually improve their modus operandi by using sophisticated machine learning, natural language processing techniques with an intent to launch successful targeted attacks aimed at deceiving detection mechanisms as well as the victims. we propose a system for advanced email masquerading attacks using natural language generation (nlg) techniques. using legitimate as well as an influx of varying malicious content, the proposed deep learning system generates emails with malicious content, customized depending on the attacker's intent. the system leverages recurrent neural networks (rnns) for automated text generation. we also focus on the performance of the generated emails in defeating statistical detectors, and compare and analyze the emails using a proposed baseline.
 we show how to build several data structures of central importance to string processing, taking as input the burrows-wheeler transform (bwt) and using small extra working space. let @math be the text length and @math be the alphabet size. we first provide two algorithms that enumerate all lcp values and suffix tree intervals in @math time using just @math bits of working space on top of the input bwt. using these algorithms as building blocks, for any parameter @math we show how to build the plcp bitvector and the balanced parentheses representation of the suffix tree topology in @math time using at most @math bits of working space on top of the input bwt and the output. in particular, this implies that we can build a compressed suffix tree from the bwt using just succinct working space (i.e. @math bits) and any time in @math . this improves the previous most space-efficient algorithms, which worked in @math bits and @math time. we also consider the problem of merging bwts of string collections, and provide a solution running in @math time and using just @math bits of working space. an efficient implementation of our lcp construction and bwt merge algorithms use (in ram) as few as @math bits on top of a packed representation of the input output and process data as fast as @math megabases per second.



Rouge score with annotator1 : 
[{'rouge-1': {'f': 0.06395086185408459, 'p': 0.8082191780821918, 'r': 0.03329257970469294}, 'rouge-2': {'f': 0.027464088138499612, 'p': 0.34782608695652173, 'r': 0.014296463506395787}, 'rouge-l': {'f': 0.09614126741758529, 'p': 0.6419213973799127, 'r': 0.051961823966065745}}]


Rouge score with annotator2 : 
[{'rouge-1': {'f': 0.06395086185408459, 'p': 0.8082191780821918, 'r': 0.03329257970469294}, 'rouge-2': {'f': 0.027464088138499612, 'p': 0.34782608695652173, 'r': 0.014296463506395787}, 'rouge-l': {'f': 0.09614126741758529, 'p': 0.6419213973799127, 'r': 0.051961823966065745}}]


Rouge score with annotator3 : 
[{'rouge-1': {'f': 0.06395086185408459, 'p': 0.8082191780821918, 'r': 0.03329257970469294}, 'rouge-2': {'f': 0.027464088138499612, 'p': 0.34782608695652173, 'r': 0.014296463506395787}, 'rouge-l': {'f': 0.09614126741758529, 'p': 0.6419213973799127, 'r': 0.051961823966065745}}]


average Rouge score : 
{'rouge-l': {'f': 0.09614126741758529, 'r': 0.051961823966065745, 'p': 0.6419213973799127}, 'rouge-2': {'f': 0.027464088138499612, 'r': 0.014296463506395787, 'p': 0.34782608695652173}, 'rouge-1': {'f': 0.06395086185408459, 'r': 0.03329257970469294, 'p': 0.8082191780821918}}


anti-redundance objective value :	nan
Average tf-idf objective value :	7.1763113333333335